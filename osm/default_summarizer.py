import os, sys
import subprocess
import numpy as np
import pandas as pd
import scipy.io as sio
import dask.dataframe as dd
from osm.campaign import isNotBlank, new_folder
from joblib import Parallel, delayed, parallel_backend


def wrapper_scavetool(input_files_directory, output_directory, output_filename):
    """

    Try to convert scalar (*.sca) and vector (*.vec) statistics generated by OMNET++ tool scavetool.

    """
    # Go to OMNET++ results folder
    os.chdir(input_files_directory)
    output_cvs_file = os.path.join(output_directory, output_filename)

    # Find scavetool OMNET++ tool to generate .csv file from scalar and vector statistics
    command = 'whereis' if os.name != 'nt' else 'which'
    r = subprocess.getoutput('{0} {1}'.format(command, 'scavetool'))
    app_instance = (r.strip('scavetool:').strip()).split(' ')
    path = app_instance[1]  # TO DO in case more than one OMNET installation is found

    # Execute scavetool

    cmd = '{}scavetool x -v *.sca *.vec -o {}'.format(path, output_cvs_file)
    print(cmd)
    os.system(cmd)


def merge_files(input_files_directory, output_directory, output_filename, additional_files_path, max_processes):
    """

    Merge repetitions executed per scenario in one output file.
    Add statistics (mean, standard deviation).

    Input: Directory with results files. File with evaluation structure.csv (i.e., Parameters evaluated in project)
    Output: One output file (*.npy, *.mat *.csv).

    """

    # Read simulation campaign results in results folder
    result_files = os.listdir(input_files_directory)
    # List additional files directory
    variables_path = os.path.join(additional_files_path, 'variables.txt')
    structure_file_path = os.path.join(additional_files_path, 'structure.csv')

    omnet_files = False
    for file in result_files:
        if file.endswith(".sca") or file.endswith(".vec"):
            omnet_files = True
            break

    if omnet_files:

        # Call OMNET scavetool tool
        wrapper_scavetool(input_files_directory, output_directory, output_filename)
        print("Output file '{}' generated with scavetool from {} OMNeT++ result files\n".format(output_filename,
                                                                                                len(result_files)))

    else:

        # Read iteration parameter to insert in file structure.csv
        iteration_parameters_dic = get_iteration_parameters(variables_path)

        # Read structure.csv
        e_parameters = get_parameters(structure_file_path)

        # results data frame
        total_results_df = pd.DataFrame()

        # No paralelized
        #results_df = results_df.append([build_results_df(input_files_directory, file, e_parameters, iteration_parameters_list) for file in result_files])

        with parallel_backend("loky"):
            total_results_df = total_results_df.append(Parallel(n_jobs=max_processes, verbose=1)(delayed(build_results_df)(input_files_directory, file, e_parameters, iteration_parameters_dic) for file in result_files))
        save_simulation_results(total_results_df, output_directory, output_filename)
        print("Output file '{}' generated from {} result files\n".format(output_filename, len(result_files)))


def get_iteration_parameters(variables_path):
    """

    Read iteration parameters from file as part of the structure.csv

    """
    with open(variables_path, 'r') as ini_file:
        # iteration variables.txt
        iter_variables_dic = {}
        for line in ini_file:
            if isNotBlank(line):
                iter_vararible, values = line.strip().split('=')
                # get array of values
                values = values.replace('{', '').replace('}', '').replace('s', '').replace(" ", "")
                values = values.split(',')
                iter_vararible = iter_vararible.strip().split('.')
                iter_variables_dic[iter_vararible[-1]] = values
    return iter_variables_dic


def add_basic_columns(summarized_df, parameters_dic, filename):
    # Insert columns with scenario, variables and repetitions per execution
    name_components = filename.split(',')
    # Column 0 filename
    summarized_df.insert(0, 'name', filename)
    # Column 1 scenario
    summarized_df.insert(1, 'scenario', name_components[0])
    # Column 2 repetitions
    summarized_df.insert(2, 'repetition', name_components[-1])
    # Match and add parameters columns
    for elem, eval_variable in enumerate(name_components[1:-1]):
        for param in parameters_dic:
            parameter_values = parameters_dic[param]
            if eval_variable.strip('-') in parameter_values:
                column_name = param
                break
        summarized_df.insert(elem + 3, '{}'.format(column_name), np.int(eval_variable.strip('-')))
    return summarized_df


def build_results_df(input_files_directory, filename, structure, iteration_parameters_dic):

    #Build dataframes from result files.
    #In case of numeric types, dataframes are constructed accordingly
    #Additional columns are add (filename, scenario, repetition) from the file name for grouping purposes.

    # read data and build a dataframe
    with open(os.path.join(input_files_directory, filename), 'r') as file:
        value = [line.strip().split(',') for line in file]
    values = np.array(value)

    # check results and structure number of elements
    if len(values[0]) == len(structure):
        # build dataframe from result file and structure.csv file (contains the columns names)
        df_results = pd.DataFrame(values, columns=structure)
        # assign numeric type to columns
        for column in df_results.columns:
            # try to convert to numeric if first row value is numeric
            if type(parse_if_number(df_results[column].iloc[0])) == float:
                df_results[column] = pd.to_numeric(df_results[column], errors='coerce')

        # Add new columns [scenario, repetitions, evaluations variables]
        summarized_df = add_basic_columns(df_results, iteration_parameters_dic, filename)
        # Add USER custom  columns
        customized_df = add_user_custom_columns(summarized_df)
        return customized_df
    else:
        sys.exit("variables.txt file and structure.txt do not has the same number of elements")


def add_user_custom_columns(default_df):
    # Add column with distance from accident node position to rx node QSN
    tx_nodes = default_df[default_df.TR == 'tx']
    accident_node = tx_nodes[tx_nodes.NodeID == 0]
    acc_x, acc_y = accident_node.at[0, 'x'], accident_node.at[0, 'y']
    # Euclidean distance
    default_df['DistanceToAccident'] = ((acc_x - default_df.x) ** 2 + (acc_y - default_df.y) ** 2) ** (1 / 2)

    return default_df


def parse_if_number(s):
    """

    Return a float, True/False or None

    """
    try:
        return float(s)
    except:
        return True if s == 'true' else False if s == 'false' else s if s else None


def get_parameters(eval_path):
    """

    Return a list of structure.csv to sort the results table.
    It must be consistent with gathered values in the project.

    Structure in structure.csv external file:

            parm1,parm2,parm3,.....

    """

    # Read structure.csv
    with open(eval_path, 'r') as eval_file:
        for line in eval_file:
            if isNotBlank(line):
                eval_param = line.strip('\n').split(',')
    return eval_param


def save_simulation_results(results_summary, output_directory, file_name):
    """

    Export results to file to supported file extension.
    The extension must be included in the filename.
    By default .npy is selected.

    Supported extensions:
         .npy (Numpy file), .mat (Matlab file) or csv (Comma-separated values) by default

    """

    new_folder(output_directory)
    name, ext = file_name.split('.')
    if ext in ['mat', 'MAT']:
        sio.savemat(os.path.join(output_directory, file_name), results_summary)
    else:
        sim_summary = dd.from_pandas(results_summary, npartitions=20)
        if ext in ['npy', 'NPY']:
            np.save(os.path.join(output_directory, file_name), sim_summary)
        else:
            # default csv file
            sim_summary.to_csv(os.path.join(output_directory, file_name), index=None, header=True, single_file=True)
