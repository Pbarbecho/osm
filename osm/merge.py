import os
import numpy as np
import pandas as pd
import scipy.io as sio
from osm import campaign
import sys
import subprocess
from joblib import Parallel, delayed, parallel_backend


def wrapper_scavetool(input_files_directory, output_directory, output_filename):
    """

    Try to convert scalar (*.sca) and vector (*.vec) statistics generated by OMNET++ tool scavetool.

    """
    # Go to OMNET++ results folder
    os.chdir(input_files_directory)
    output_cvs_file = os.path.join(output_directory, output_filename)

    # Find scavetool OMNET++ tool to generate .csv file from scalar and vector statistics
    command = 'whereis' if os.name != 'nt' else 'which'
    r = subprocess.getoutput('{0} {1}'.format(command, 'scavetool'))
    app_instance = (r.strip('scavetool:').strip()).split(' ')
    path = app_instance[0]  # TO DO in case more than one OMNET installation is found

    # Execute scavetool
    cmd = '{} x *.sca *.vec -o {}'.format(path, output_cvs_file)
    os.system(cmd)


def merge_files(input_files_directory, output_directory, output_filename, eval_path, max_processes, variables_path):
    """

    Merge repetitions executed per scenario in one output file.
    Add statistics (mean, standard deviation).

    Input: Directory with results files. File with evaluation structure_file (i.e., Parameters evaluated in project)
    Output: One output file (*.npy, *.mat *.csv).

    """

    # Read simulation campaign results in results folder
    result_files = os.listdir(input_files_directory)

    omnet_files = False
    for file in result_files:
        if file.endswith(".sca") or file.endswith(".vec"):
            omnet_files = True
            break

    if omnet_files:

        # Call OMNET scavetool tool
        wrapper_scavetool(input_files_directory, output_directory, output_filename)
        print("Output file '{}' generated with scavetool from {} OMNeT++ result files\n".format(output_filename,
                                                                                                len(result_files)))

    else:

        # Read iteration parameter to insert in file structure
        iteration_parameters_list = get_iteration_parameters(variables_path)

        # Read structure_file
        e_parameters = get_parameters(eval_path)

        # results data frame
        total_results_df = pd.DataFrame()

        # No paralelized
        #results_df = results_df.append([build_results_df(input_files_directory, file, e_parameters, iteration_parameters_list) for file in result_files])

        with parallel_backend("loky"):
            total_results_df = total_results_df.append(Parallel(n_jobs=max_processes, verbose=1)(delayed(build_results_df)(input_files_directory, file, e_parameters, iteration_parameters_list) for file in result_files))
        save_simulation_results(total_results_df, output_directory, output_filename)
        print("Output file '{}' generated from {} result files\n".format(output_filename, len(result_files)))


def get_iteration_parameters(variables_path):
    """

    Read iteration parameters from file as part of the structure

    """

    with open(variables_path, 'r') as ini_file:
        # iteration variables
        iter_vararibles_list = []
        for line in ini_file:
            if campaign.isNotBlank(line):
                iter_vararible, value = line.split('=')
                iter_vararible = iter_vararible.strip().split('.')
                iter_vararibles_list.append(iter_vararible[-1])
    return iter_vararibles_list


def build_results_df(input_files_directory, filename, structure, iteration_parameters_list):
    """

    Build dataframes from result files.
    In case of numeric types, dataframes are constructed accordingly
    Additional columns are add (filename, scenario, repetition) from the file name for grouping purposes.
    """

    #iteration_parameters_list = iteration_parameters_list[::-1]
    # read data and build a dataframe
    with open(os.path.join(input_files_directory, filename), 'r') as file:
        value = [line.strip().split(',') for line in file]
    values = np.array(value)

    if len(values[0]) == len(structure):

        # build dataframe from result file and structure file (contains the columns names)
        df_results = pd.DataFrame(values, columns=structure)
        # assign numeric type to columns
        for column in df_results.columns:
            # try to convert to numeric if first value is numeric
            if type(parse_if_number(df_results[column].iloc[0])) == float:
                df_results[column] = pd.to_numeric(df_results[column], errors='coerce')

        # insert columns with filename, scenario and repetitions per execution
        name_components = filename.split(',')
        df_results.insert(0, 'name', filename)

        for i, component in enumerate(name_components):
            if i == 0:
                df_results.insert(i + 1, 'scenario', component)
            if i >= 1:
                if i + 1 == len(name_components):
                    df_results.insert(i + 1, 'repetition', component)
                else:
                    df_results.insert(i + 1, '{}'.format(iteration_parameters_list[i-1]), component)
        return df_results

    else:
        print('Number of structure_file must be equal to structure_file in results files!!!')
        sys.exit()


def parse_if_number(s):
    """

    Return a float, True/False or None

    """
    try:
        return float(s)
    except:
        return True if s == 'true' else False if s == 'false' else s if s else None


def get_parameters(eval_path):
    """

    Return a list of structure_file to sort the results table.
    It must be consistent with gathered values in the project.

    Structure in structure_file external file:

            parm1,parm2,parm3,.....

    """

    # Read structure_file
    with open(eval_path, 'r') as eval_file:
        for line in eval_file:
            if campaign.isNotBlank(line):
                eval_param = line.strip('\n').split(',')
    return eval_param


def save_simulation_results(sim_summary, output_directory, file_name):
    """

    Export results to file to supported file extension.
    The extension must be included in the filename.
    By default .npy is selected.

    Supported extensions:
         .npy (Numpy file), .mat (Matlab file) or csv (Comma-separated values) by default

    """

    campaign.new_folder(output_directory)
    name, ext = file_name.split('.')
    if ext in ['npy', 'NPY']:
        np.save(os.path.join(output_directory, file_name), sim_summary)
    elif ext in ['mat', 'MAT']:
        sio.savemat(os.path.join(output_directory, file_name), sim_summary)
    else:
        # default csv file
        sim_summary.to_csv(os.path.join(output_directory, file_name), index=None, header=True)
